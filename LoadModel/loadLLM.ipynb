{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6fcb2925da48e5a1adca4644cc0d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdel\\.conda\\envs\\ML\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abdel\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ee38e768b64ffa9156479c9c98dbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try chatting with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert in IA and you assist people with building their IA systems and fine tuning large language models based on their needs.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hey, what is the best way to fine tune a large language model based on my data, which is a set of research papers?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted chat:\n",
      " <｜begin▁of▁sentence｜>You are an expert in IA and you assist people with building their IA systems and fine tuning large language models based on their needs.<｜User｜>Hey, what is the best way to fine tune a large language model based on my data, which is a set of research papers?<｜Assistant｜>\n"
     ]
    }
   ],
   "source": [
    "formatted_chat = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "print(\"Formatted chat:\\n\", formatted_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(formatted_chat, return_tensors=\"pt\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=2048, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded output:\n",
      " <think>\n",
      "Okay, so I need to figure out the best way to fine tune a large language model based on my data, which is a set of research papers. I'm not entirely sure where to start, but I know that fine tuning involves adjusting the model to better fit the data I have. Let me break this down step by step.\n",
      "\n",
      "First, I should probably understand what exactly fine tuning is. From what I remember, it's about making the model more accurate by tweaking its parameters based on the data it's trained on. So, if I have a bunch of research papers, I need to see how the model performs on those documents and adjust it accordingly.\n",
      "\n",
      "I think the first thing I should do is assess how well the model currently is performing. Maybe I can look at some metrics like accuracy, BLEU score, or other relevant evaluation metrics. But wait, how do I get accurate metrics from research papers? I guess I need to parse the papers and extract relevant information that the model can understand. That might be a bit tricky because the papers are in natural language, not just a fixed vocabulary.\n",
      "\n",
      "Once I have the model's current performance, I can start fine-tuning. I remember reading that fine-tuning involves adding more data to the model. So, I should probably collect more research papers or similar documents to train the model on. But how do I decide which papers to include? Maybe I can categorize them based on the topics or the type of information they contain. For example, if I'm fine-tuning for a specific task like summarization, I should focus on research papers related to that task.\n",
      "\n",
      "I also need to consider the structure of the research papers. They might have different formats, like abstracts, introduction, literature review, etc. I should make sure the model can handle all these parts. Maybe I can preprocess each paper by extracting key information, like the main topic, the arguments, or the conclusions, and then feed that into the model.\n",
      "\n",
      "Another thing I'm thinking about is the amount of data I need. If I have a lot of research papers, the model might take a long time to train. I should probably start with a smaller dataset and see how it goes. If it's not performing well, I can gradually increase the size of the dataset. But how do I determine the right size? Maybe I can use some validation techniques, like cross-validation, to test different sizes and find the optimal amount.\n",
      "\n",
      "I also need to think about the parameters of the model. Fine-tuning involves adjusting hyperparameters like learning rate, batch size, and the number of iterations. I should probably start with reasonable values and then adjust them based on the results. For example, if the model is learning too slowly, I might need to increase the learning rate. But I have to be careful not to make it too fast, which could cause the model to overshoot the correct answer.\n",
      "\n",
      "I'm also wondering about the evaluation metrics. Since the data is research papers, I need to make sure I'm using appropriate metrics. BLEU is commonly used for text generation, but for summarization or summarizing research papers, maybe ROUGE or other metrics would be more suitable. I should probably look up some evaluation metrics that are suitable for research papers and use them to assess the model's performance.\n",
      "\n",
      "Another consideration is the computational resources. Training a large language model on a dataset of research papers might require a lot of processing power and memory. I should check if my hardware is sufficient and if I need to optimize the model or the data preprocessing steps to make it run faster.\n",
      "\n",
      "I also need to think about the quality of the data. If the research papers are from reliable sources and are well-structured, that would be great. But if there are errors or inconsistencies, that could affect the model's performance. I should probably preprocess the data to clean it up and handle any issues that come up.\n",
      "\n",
      "I'm also curious about how to handle different languages or topics within the research papers. If the model is fine-tuned for a specific language, I need to ensure that it can handle variations. Maybe I can use multilingual models or adapt the model to different languages during training.\n",
      "\n",
      "I should also consider the time it will take to fine-tune the model. If I'm starting from scratch, it might take a long time, but if I have some existing knowledge, maybe I can use that as a starting point. I should probably outline the steps I plan to take and set a timeline for each phase.\n",
      "\n",
      "In summary, the steps I think I need to take are:\n",
      "\n",
      "1. Assess the current performance of the model using evaluation metrics on the research papers.\n",
      "2. Preprocess the research papers to extract relevant information and structure them in a way the model can understand.\n",
      "3. Fine-tune the model by adding more research papers to the dataset, adjusting hyperparameters, and evaluating performance at each step.\n",
      "4. Validate the fine-tuned model on a separate dataset to ensure it generalizes well and doesn't overfit to the training data.\n",
      "5. Iterate and adjust the model as needed based on the results.\n",
      "\n",
      "I'm not entirely sure about all these steps, especially how to preprocess the research papers and evaluate the performance. I might need to look up some resources or examples of fine-tuning large language models on research papers to get a better idea. Also, I'm a bit confused about the exact evaluation metrics for research papers. I think I need to do some research on that to make sure I'm using the right metrics.\n",
      "\n",
      "Another thing I'm thinking about is the computational efficiency. Training a large model on a dataset of research papers might be computationally intensive. I should probably look into using efficient hardware or optimizing the model and data preprocessing steps to make the training process faster.\n",
      "\n",
      "I also wonder about the role of transfer learning in this process. Since the research papers are likely related to a specific domain, maybe I can leverage transfer learning to fine-tune the model without retraining it from scratch. That could save time and resources.\n",
      "\n",
      "Lastly, I need to think about the ethical implications of fine-tuning a model based on research papers. I should make sure that the fine-tuning process is transparent and that the model's decisions are based on accurate and relevant information from the research papers.\n",
      "\n",
      "Overall, I think the key steps are to assess the model's current performance, preprocess the data, fine-tune the model, validate it, and iterate as needed. I need to make sure I'm using appropriate evaluation metrics and efficient computational resources to make this process feasible.\n",
      "</think>\n",
      "\n",
      "To fine tune a large language model based on a dataset of research papers, follow these organized steps:\n",
      "\n",
      "1. **Assess Current Performance:**\n",
      "   - Evaluate the model's performance using appropriate metrics such as accuracy, BLEU score, or ROUGE for summarization tasks.\n",
      "   - Preprocess the research papers to extract relevant information and structure them in a way the model can understand.\n",
      "\n",
      "2. **Preprocess Research Papers:**\n",
      "   - Clean and preprocess the research papers to handle errors, inconsistencies, and formatting issues.\n",
      "   - Extract key information such as main topics, arguments, and conclusions to feed into the model.\n",
      "\n",
      "3. **Fine-Tune the Model:**\n",
      "   - Start with a smaller dataset and gradually increase its size to optimize the model's learning.\n",
      "   - Adjust hyperparameters such as learning rate, batch size, and number of iterations based on evaluation metrics.\n",
      "   - Use appropriate evaluation metrics suitable for research papers, such as ROUGE or other metrics, to assess performance.\n",
      "\n",
      "4. **Validation and Iteration:**\n",
      "   - Validate the fine-tuned model on a separate dataset to ensure generalization and avoid overfitting.\n",
      "   - Iterate and adjust the model as needed based on results, considering computational efficiency and ethical implications.\n",
      "\n",
      "5. **Consider Transfer Learning:**\n",
      "   - Leverage transfer learning to fine-tune the model without retraining from scratch, saving time and resources.\n",
      "\n",
      "6. **Ethical Considerations:**\n",
      "   - Ensure transparency and fairness in the fine-tuning process, focusing on accurate and relevant information from research papers.\n",
      "\n",
      "By following these steps, you can effectively fine tune your model to perform well on research papers, ensuring it is both accurate and ethically sound.\n"
     ]
    }
   ],
   "source": [
    "decoded_output = tokenizer.decode(outputs[0][inputs['input_ids'].size(1):], skip_special_tokens=True)\n",
    "print(\"Decoded output:\\n\", decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../cache/training_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"../cache/training_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../cache/fine_tuned_model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    logging_dir=\"../cache/logs\",\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
